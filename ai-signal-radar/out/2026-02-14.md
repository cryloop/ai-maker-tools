# AI Signal Radar — 2026-02-14

Sources: Hugging Face blog, arXiv cs.AI RSS, r/LocalLLaMA RSS, HN Algolia query.

## Hugging Face — Blog
- [Custom Kernels for All from Codex and Claude](https://huggingface.co/blog/custom-cuda-kernels-agent-skills) (2026-02-13)
- [OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments](https://huggingface.co/blog/openenv-turing) (2026-02-12)
- [Transformers.js v4 Preview: Now Available on NPM!](https://huggingface.co/blog/transformersjs-v4) (2026-02-09)
- [Introducing SyGra Studio](https://huggingface.co/blog/ServiceNow-AI/sygra-studio) (2026-02-05)
- [Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model](https://huggingface.co/blog/nvidia/nemotron-colembed-v2) (2026-02-04)

## arXiv — cs.AI
- (no items fetched)

## Reddit — r/LocalLLaMA
- [AMA with MiniMax — Ask Us Anything!](https://www.reddit.com/r/LocalLLaMA/comments/1r3t775/ama_with_minimax_ask_us_anything/) (2026-02-13)
- [Announcing LocalLlama discord server & bot!](https://www.reddit.com/r/LocalLLaMA/comments/1mpk2va/announcing_localllama_discord_server_bot/) (2025-08-13)
- [models : optimizing qwen3next graph by ggerganov · Pull Request #19375 · ggml-org/llama.cpp](https://www.reddit.com/r/LocalLLaMA/comments/1r4hx24/models_optimizing_qwen3next_graph_by_ggerganov/) (2026-02-14)
- [local vibe coding](https://www.reddit.com/r/LocalLLaMA/comments/1r4hhyy/local_vibe_coding/) (2026-02-14)
- [The gap between open-weight and proprietary model intelligence is as small as it has ever been, with Claude Opus 4.6 and GLM-5'](https://www.reddit.com/r/LocalLLaMA/comments/1r44fzk/the_gap_between_openweight_and_proprietary_model/) (2026-02-13)

## Hacker News
- [LLM Inevitabilism](https://tomrenner.com/posts/llm-inevitabilism/) (1773 points, 2025-07-15)
- [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/) (1654 points, 2024-09-12)
- [LLM Visualization](https://bbycroft.net/llm) (1592 points, 2023-12-03)
- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL](https://arxiv.org/abs/2501.12948) (1351 points, 2025-01-25)
- [A small number of samples can poison LLMs of any size](https://www.anthropic.com/research/small-samples-poison) (1202 points, 2025-10-09)

## 3 quick follow-ups (auto-generated heuristics)
- Skim HF blog post titles for tooling you can *ship* this week (agents, evals, runtimes).
- Pull 1 arXiv paper that suggests a measurable technique; write a minimal reproduction script.
- From r/LocalLLaMA + HN: identify 1 recurring pain point; build a tiny CLI to reduce it.
